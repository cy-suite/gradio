{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b01cc195",
   "metadata": {},
   "source": [
    "# Gradio Demo: blocks_speech_text_sentiment\n",
    "\n",
    "\n",
    "#### THIS NOTEBOOK IS AUTOGENERATED. DO NOT EDIT THIS FILE DIRECTLY: Edit the corresponding run.py file in the `gradio/demo` directory and run `python generate_notebooks.py` to regenerate this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q gradio torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665f4204",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "asr = pipeline(\"automatic-speech-recognition\", \"facebook/wav2vec2-base-960h\")\n",
    "classifier = pipeline(\"text-classification\")\n",
    "\n",
    "\n",
    "def speech_to_text(speech):\n",
    "    text = asr(speech)[\"text\"]\n",
    "    return text\n",
    "\n",
    "\n",
    "def text_to_sentiment(text):\n",
    "    return classifier(text)[0][\"label\"]\n",
    "\n",
    "\n",
    "demo = gr.Blocks()\n",
    "\n",
    "with demo:\n",
    "    audio_file = gr.Audio(type=\"filepath\")\n",
    "    text = gr.Textbox()\n",
    "    label = gr.Label()\n",
    "\n",
    "    b1 = gr.Button(\"Recognize Speech\")\n",
    "    b2 = gr.Button(\"Classify Sentiment\")\n",
    "\n",
    "    b1.click(speech_to_text, inputs=audio_file, outputs=text)\n",
    "    b2.click(text_to_sentiment, inputs=text, outputs=label)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
